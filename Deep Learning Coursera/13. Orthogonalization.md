# Introduction
* Orthogonalization can be analogous to modular codes/programming styles.
* Each module performing only one specific task.

# Assumptions in ML
* Fit training set well on cost function
    * Bigger network
    * Changing models etc.
* Fit dev set well on cost function
    * Regularization
    * Bigger training set
* Fit test set well on cost function
    * Bigger dev set
* Performs well in real world
    * Change dev set or cost function or both.

# Extras
* Always use a single number evaluation metric
    * This ensures that you are not confused as to which model to choose it one of the values is greater in one model and other in other model.
* If our accuracy is under a constraint such as running time, then it is called satisficing varaible and accuracy is called optimizing variable.
* Hence, if there are n metrics then 1 can be optimizing metric and rest n - 1 are satisficing metrics.
* Make sure that the dev and test set come from the same distribution for obvious reasons.
* What should be the size of these sets?
    * Set your test set to be big enough to give high confidence in the overall performance of your system.