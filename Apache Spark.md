# What is it?
* Multi-language engine for executing data engineering, data science and machine learning on single-node machines or clusters.
* Used especially for Big Data of petabyte scale.

# Advantages
* Both Batch and Streaming data processing
* SQL Analytics
* Scalable
* Can handle petabyte level data easily
* Integrates variety of frameworks like scikit-learn, pandas, tensorflow, python, R, Scala, Java etc.
* Uses distributed SQL engine.
* Can handle Structured as well as unstructured data.

# PySpark Tutorial
* [Link](https://spark.apache.org/docs/latest/api/python/index.html)
* SQL Engine, work with python APIs.
* Distributed SQL Engine.
* Does not execute right away. First creates a plan like how many reducers to use etc.
* Then, on calling connect(), executes.
* PySpark starts by starting a session.