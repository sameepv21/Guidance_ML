# What is it?
* Describes your ML process
    * Reading data and converting to pandas dataframe
    * Dropping or adding some columns
    * Running some calculations over the columns
    * Normalizing the data
    * Performing data extractions
    * Creating training models
    * Tuning the algorithm
    * Releasing it to production
* Used to help automate machine learning workflows.
* Are iterative as every step is repeated to continuously improve the accuracy of the model.
* Main objective is to exercise control over the ML model.
* They are cyclic in nature, makes model scalable.
* A pipeline consists of sequence of components which are a compilation of computation.

# Processes
* Data Collection
* Data Clearning
* Feature Extraction (Labelling and Dimensionality reduction)
* Model Validation
* Visualisation

# Extras
* Captured data should be pulled and put together and the benefits of collection should outweight the costs of collection and analysis.
* Data lake is thus recommended which is just a centralised repository that allows the user to store both structured and unstructured data at any scalable.
    * Enables ad-hoc analysis.
    * Only read, not write.
    * Can apply multiple analtics and processing frameworks to the same data.
 

# Resources
* [Starting Guidelines](https://medium.com/analytics-vidhya/what-is-a-pipeline-in-machine-learning-how-to-create-one-bda91d0ceaca)